{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctiques de Nous Usos de la Informàtica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom de les persones del grup:** Pau Sanchez Valdivieso i Albert Espín Román"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 2. Recomanadors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcció d'un recomanador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lectura de dades\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "users = pd.read_table('ml-1m/users.dat', sep='::', header=None, names=unames, engine='python')\n",
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table('ml-1m/ratings.dat', sep='::', header=None, names=rnames, engine='python')\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('ml-1m/movies.dat', sep='::', header=None, names=mnames, engine='python')\n",
    "\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "\n",
    "# Limitem el nombre d'usuaris per a fer possible veure els resultats d'exercicis posteriors en poques hores\n",
    "# Deixem en canvi totes les pel·lícules\n",
    "data = data[data.user_id < 3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alerta**: Les implementacions dels exercicis 6, 7 i 8 poden tardar molt en executar-se, considera fer-ho en un subset de les dades originals. En la 1a cel·la:\n",
    "```\n",
    "    data = data[data.user_id < 100]\n",
    "    data = data[data.movie_id < 100]\n",
    "```\n",
    "El codi anterior limitaria les dades a 100 usuaris i 100 películes. Recorda re-executar les cel·les.\n",
    "\n",
    "Com a guia, una implementació que usi N usuaris i películes, per l'exercici 6, ot arribar a trigar:\n",
    "\n",
    "* N=100, 5 segons a 60 segons\n",
    "* N=1000, 15 minuts a 1 hora\n",
    "* N=10000, 20 hores a 60 hores\n",
    "\n",
    "segons la implementació utilitzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El següent codi, donat el conjunt de dades, construeix un conjunt d'entrenament i un conjunt  de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generem subconjunts de training i test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    df.ix[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "data['for_testing'] = False\n",
    "grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "movielens_train = data[grouped.for_testing == False]\n",
    "movielens_test = data[grouped.for_testing == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La següent funció `evaluate(estimate)`, donat un conjunt de dades d'entrenament i un conjunt de dades de test ens avalua la precisió d'un sistema de recomanació que li passem per paràmetre. Per a cadascun dels elements del conjunt de test haurem de pronosticar el seu valor i comparar-lo amb el valor real que l'usuari li ha asignat. La mesura que utilizarem per avaluar el sistema és la root-mean-square error (rsme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definim una funció per avaluar el resultat de la recomanació.\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def evaluate(estimate,test=movielens_test):\n",
    "    ids_to_estimate = zip(test['user_id'], test['movie_id'])\n",
    "    estimated = np.array([estimate(u,i) for (u,i) in ids_to_estimate])\n",
    "    real = test.rating.values\n",
    "    nans = np.isnan(estimated)\n",
    "    return compute_rmse(estimated[~nans], real[~nans])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 4\n",
    "\n",
    "+ Construeix dues funcions, `dist_euclid(x,y)` i `coef_pearson(x,y)`, que implementin la distància Euclidiana i el coeficient de correlació de Pearson entre dos vectors usant funcions de pandas. \n",
    "\n",
    "+ Escriu les funcions que calculin la semblança entre dos series d'un DataFrame de Pandas. S'utiltizaran per calcular les similituds entre usuaris o entre items:\n",
    "\n",
    "    + ``def sim_euclid (data_frame, row1, row2)``\n",
    "    Calcula els vectors representatius de cada fila, C1 i C2, amb les puntuacions de les columnes que estan presents en ambdós files. En el cas dels usuaris (files), això implica trobar les películes (columnes) que han puntuat tots dos.<br />Si no hi ha puntuacions en comú, retornar 0. En cas contrari, retornar ``1/(1+dist_euclid(C1, C2))``\n",
    "\n",
    "    + ``def sim_pearson (data_frame, row1, row2)``\n",
    "    Calcular els vectors representatius de cada fila, C1 i C2, amb les puntuacions de les columnes que estan presents en ambdós files.<br />Si no hi ha puntuacions en comú, retornar 0. Retornar ``coef_pearson(C1,C2)``\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sc\n",
    "\n",
    "# nombre mínim de pel·lícules que han d'haver valorat dos usuaris per a considerar-se\n",
    "# fiable el seu valor de semblança\n",
    "minimum_common_ratings = 3\n",
    "\n",
    "def dist_euclid(x, y):\n",
    "    \"\"\" Returns the euclidean distance of two vectors \"\"\"\n",
    "    return np.linalg.norm(np.array(x) - np.array(y))\n",
    "\n",
    "def coef_pearson(x, y):\n",
    "    \"\"\" Returns the Pearson correlation of two vectors \"\"\"\n",
    "    return sc.pearsonr(x, y)[0]\n",
    "\n",
    "def clean_rows(function):\n",
    "    \"\"\" Decorador que neteja les files de manera que només conserva els elements no nuls en ambdues \"\"\"\n",
    "    \n",
    "    def wrapper(data_frame, row1, row2) :\n",
    "        common = data_frame.ix[[row1, row2]].dropna(axis=1)\n",
    "        \n",
    "        '''fixem el requisit que dos usuaris hagin valorat un cert nombre mínim de pel·lícules\n",
    "        en comú per a poder calcular un valor de similitud entre ells, altrament considerem que\n",
    "        no tenim prou dades per determinar-ho rigorosament i descartem el càlcul. El valor que\n",
    "        experimentalment hem trobat que funciona millor amb aquest recomanador és el d'un mínim\n",
    "        de 3 pel·lícules en comú'''\n",
    "        if len(common.columns) <= minimum_common_ratings:\n",
    "            return np.nan\n",
    "    \n",
    "        return function(data_frame, common.ix[row1], common.ix[row2])\n",
    "    return wrapper\n",
    "\n",
    "@clean_rows\n",
    "def sim_euclid(data_frame, row1, row2):\n",
    "    \"\"\" Returns a distance-based similarity score for person1 and person2 based on euclidean distance \"\"\"\n",
    "    return 1 / (1 + dist_euclid(row1, row2))\n",
    "\n",
    "\n",
    "@clean_rows\n",
    "def sim_pearson(data_frame, row1, row2):\n",
    "    \"\"\" Returns a distance-based similarity score for person1 and person2 based on pearson distance \"\"\"\n",
    "    return coef_pearson(row1, row2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests de les funcions, pots realitzar modificacions prèvies a les taules (per exemple, agrupar o pivotar) per accelerar el procés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333333333\n",
      "0.416666666667\n"
     ]
    }
   ],
   "source": [
    "# Test de les funcions de similitud sobre els usuaris 1 i 2 (NaN indicaria que no tenen prou\n",
    "# valoracions en comú com per a poder calcular un valor de similitud)\n",
    "\n",
    "ratings = data.pivot_table(values=\"rating\", index=\"user_id\", columns=\"movie_id\")\n",
    "\n",
    "print sim_euclid(ratings, 1, 2)\n",
    "print sim_pearson(ratings, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 5\n",
    "\n",
    "+ Feu dues funcions, ``get_best_euclid(data_frame, user, n)`` i ``get_best_pearson(data_frame, user, n)``, que retornin els ``n`` usuaris més semblants segons aquestes dues mesures de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_maximum_values(values, n):\n",
    "    \"\"\" Obté els n majors valors presents a la llista de tuples, on el valor d'índex\n",
    "        1 de la tupla és el valor numèric a tenir en compte\"\"\"\n",
    "    \n",
    "\n",
    "    '''EL següent bucle calcula els n valors màxims a la llista de tuples. En quant a la\n",
    "    implementació, som conscients que es pot fer en una línia mitjançant la funció sort()\n",
    "    d'ordenació i quedant-nos amb el n primers elements, però aquesta funció té complexitat\n",
    "    O(m log m), sent m la mida de llista de valors. Hem preferit anar cercant el màxim de cada\n",
    "    iteració i extraient-lo de la llista ja que cercar el màxim un cop és O(m), i n cops és \n",
    "    O(n * m), sent n el nombre de valors màxims a obtenir, sent generalment n un valor molt\n",
    "    petit comparat amb m, podent-se aproximar a O(m), assumint que numpy implementa un algorisme\n",
    "    d'eliminació d'un element prou eficient, i considerant negligibles la resta d'operacions,\n",
    "    de caire senzill.\n",
    "    '''\n",
    "    max_values = []\n",
    "    \n",
    "    while len(max_values) < n and values:\n",
    "        max_value = max(values, key=lambda x : x[1])\n",
    "        \n",
    "        if not np.isnan(max_value[1]):\n",
    "            max_values.append(max_value)\n",
    "        values.remove(max_value)\n",
    "\n",
    "    return max_values\n",
    "\n",
    "\n",
    "def get_best_euclid(data_frame, user, n):\n",
    "    \"\"\" Retorna els n usuaris més similars a l'usuari indicat segons el criteri de similitud euclidiana \"\"\"\n",
    "    similarities = [(i, sim_euclid(data_frame, i, user)) for i in data_frame.index if i != user]\n",
    "    return get_maximum_values(similarities, n)\n",
    "       \n",
    "\n",
    "def get_best_pearson(data_frame, user, n):\n",
    "    \"\"\" Retorna els n usuaris més similars a l'usuari indicat segons el criteri de similitud de Pearson \"\"\"\n",
    "    similarities = [(i, sim_pearson(data_frame, i, user)) for i in data_frame.index if i != user]\n",
    "    return get_maximum_values(similarities, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(526, 1.0), (1455, 1.0), (2426, 1.0), (2558, 1.0), (2733, 1.0)]\n",
      "[(526, 1.0), (1056, 1.0), (1388, 1.0), (1455, 1.0), (2426, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "'''Petit test de les funcions anteriors, cercant els 5 usuaris més similars a l'usuari 1, amb\n",
    "els seus valors de semblança. En cas de mostrar-se menys dels esperats es deurà a que no hi ha\n",
    "suficients usuaris que hagin valorat el mateix (això només passa amb bases de dades petites o\n",
    "si l'usuari ha valorat molt poques pel·lícules). Observem com el mètode de Pearson s'abstrau de\n",
    "la inflació de les puntuacions, per la qual cosa resulta més versàtil.'''\n",
    "\n",
    "print get_best_euclid(ratings, 1, 5)\n",
    "print get_best_pearson(ratings, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 6\n",
    "\n",
    "En l'exercici 6 i 7 es desenvoluparà un sistema de recomanació basat en usuaris i en ítems, respectivament.\n",
    "\n",
    "El codi donat, que es basa en 3 classes, és la recomenada per fer-ho òptim i reaprofitar el màxim de codi, però s'acceptaran solucions que no la segueixin, sempre hi quan respectin el mètode \"estimate\" explicat més abaix i funcionin de forma correcte.\n",
    "\n",
    "#### `CollaborativeFiltering`\n",
    "\n",
    "Una classe base, comuna en els 2 recomanadors, que implementarà:\n",
    "  \n",
    "  * `__init__`: Rep com a paràmetres el dataframe (que constarà de `user_id`, `movie_id` i `rating`), la funció de semblança (Euclidiana o Pearson) que volem usar i un paràmetre `M` que indica el tamany que tindrà la matriu de similituds.\n",
    "  \n",
    "  * `precompute`: Generar per cada estimació la semblança entre 2 usuaris o items seria molt costós i faria l'algorisme molt lent, per tant, aquesta funció omplirà la taula MxM (on M es el número de usuaris o items, segons el recomanador) amb el coeficient de semblança.\n",
    "      * Nota: La taula es un DataFrame de Pandas, per tant accedirem als element fent servir l'indexat de Pandas (que correspon al id del user/movie, i no a la posició 0...i)\n",
    "  \n",
    "  * `estimate`: s'encarrega de donar la predicció, en aquest cas donat un usuari i una pel·lícula estimar el seu rating.\n",
    "    + Nota 1: Si un `user_id` o `movie_id` no es troba en el DataFrame, cal retornar \"np.NAN\"\n",
    "    + Nota 2: En el recomenador d'usuaris, s'ha d'evitar comparar `user_id` a ell mateix. De la mateixa forma, en el d'items evitarem comparar un `movie_id` amb sí mateix.\n",
    "\n",
    "#### `UserRecomender`\n",
    "\n",
    "Recomanador basat en usuaris que hereta de `CollaborativeFiltering`. Implementarà:\n",
    "\n",
    "  * `__init__`: Pot realitzar transformacions al DataFrame\n",
    "  \n",
    "#### `ItemRecomender`\n",
    "\n",
    "Recomanador basat en items que hereta de `CollaborativeFiltering`. Implementarà:\n",
    "\n",
    "  * `__init__`: Pot realitzar transformacions al DataFrame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mínim valor de semblança entre un element i un altre per tal que aquest darrer es tingui en \n",
    "# compte en el procés ponderat de recomanació (establert després d'experimentar amb diversos valors)\n",
    "minimum_calculus_similarity = 0.2\n",
    "\n",
    "class CollaborativeFiltering(object):\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, data, M, similarity=sim_pearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method = similarity # Gets recommendations for a person by using a weighted average\n",
    "        self.ratings = data \n",
    "        self.sim = pd.DataFrame(0, index=M, columns=M)\n",
    "    \n",
    "    def precompute(self):\n",
    "        \"\"\"Prepare data structures for estimation. Compute similarity matrix self.sim\"\"\"\n",
    "      \n",
    "        '''Aquí preprocessem la matriu de semblances de tots els usuaris respecte tots (considerant\n",
    "        similitud inclassificable, NaN, per a un usuari amb ell mateix). Com la matriu és simètrica,\n",
    "        només cal fer la meitat dels càlculs, o dit d'una manera, omplir dos cel·les per càlcul.'''\n",
    "    \n",
    "        # Realització dels càlculs amb un diccionari\n",
    "        symetry = {}\n",
    "        for first_user in self.ratings.index:\n",
    "            for second_user in self.ratings.index:\n",
    "                if first_user != second_user:\n",
    "                    if not symetry.has_key((first_user, second_user)):\n",
    "                        symetry[(first_user, second_user)] = self.sim_method(self.ratings, first_user, second_user)\n",
    "                        symetry[(second_user, first_user)] = symetry[(first_user, second_user)]\n",
    "                else:\n",
    "                    symetry[(first_user, second_user)] = np.nan\n",
    "                    symetry[(second_user, first_user)] = symetry[(first_user, second_user)]\n",
    "           \n",
    "        # Assignació dels valors trobats a cada cel·la de la matriu de semblances\n",
    "        for key, value in symetry.iteritems():\n",
    "            self.sim.loc[key[0], key[1]] = value\n",
    "            \n",
    "    \n",
    "    def estimate(self, row, col):\n",
    "        \"\"\" Funció d'estimació genèrica utilitzada pels recomanadors subclasse\"\"\"\n",
    "        \n",
    "        # descartem els paràmetres si algun d'ells no apareix a la taula de valoracions\n",
    "        if not row in self.ratings.index or not col in self.ratings.columns:\n",
    "            return np.nan\n",
    "        \n",
    "        '''A continuació es calcula un valor de recomanació. Primerament s'escullen els elements\n",
    "        canditats, deixant-se fora els massa diferentsa l'element per al qual es farà l'estimació,\n",
    "        ja que experimentalment s'ha trobat més precís, i obviament descartant també un candidat\n",
    "        si resulta ser l'element de l'estimació.'''\n",
    "        \n",
    "        row_sim_tuples = zip(self.sim.ix[row].index, self.sim.ix[row].values)\n",
    "        row_sim_arrays = map(list, row_sim_tuples)\n",
    "        row_sim_arrays = filter(lambda x: x[0] != row, row_sim_arrays)\n",
    "        max_row_sim_arrays  = filter(lambda x : x[1] > minimum_calculus_similarity, row_sim_arrays)\n",
    "        \n",
    "        \n",
    "        '''Un cop escollits els candidats, es calcula la suma de les seves valoracions de forma\n",
    "        ponderada, és a dir, multiplicant pel seu valor de semblança amb l'element per al qual\n",
    "        es fa l'estimació. Això és pot entendre (tenint en compte que la similitud màxima és 1)\n",
    "        com que es dóna major credibilitat o importància als candidats considerats més similars.\n",
    "        La suma de valoracions ponderades normalitzada per la suma de semblances ens dóna una\n",
    "        predicció per a l'element de l'estimació, que és la que es retorna.'''\n",
    "        \n",
    "        for array in max_row_sim_arrays:\n",
    "            \n",
    "            array.append(self.ratings.loc[array[0], col])\n",
    "\n",
    "        max_row_sim_arrays = filter(lambda x: not np.isnan(x[2]), max_row_sim_arrays)\n",
    "        \n",
    "        weighted_ratings_sum = 0\n",
    "        sim_sum = 0\n",
    "        \n",
    "        for array in max_row_sim_arrays:\n",
    "            weighted_ratings_sum += array[1] * array[2]\n",
    "            sim_sum += array[1]\n",
    "            \n",
    "        recommendation_value = np.nan\n",
    "        \n",
    "        if sim_sum != 0:\n",
    "             recommendation_value = weighted_ratings_sum / sim_sum\n",
    "        \n",
    "        return recommendation_value\n",
    "    \n",
    "    \n",
    "    def get_best_recommendations(self, movie_recommendation_dict, n):\n",
    "        \"\"\"Es retornen les n millors pel·lícules més recomanables de les presents al diccionari\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        '''Aquí tornem a fer valer allò que hem dit a l'exercici 5 sobre evitar un sort() a\n",
    "        l'hora de calcular els n màxims per tal de reduir la complexitat (consultar l'exercici\n",
    "        5 per a més detalls)'''\n",
    "        while len(recommendations) < n and movie_recommendation_dict:\n",
    "            movie = max(movie_recommendation_dict, key = lambda x : movie_recommendation_dict[x])\n",
    "            recommendations.append(movie)\n",
    "            del movie_recommendation_dict[movie]\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    \n",
    "    def get_recommendations_with_titles(self, best_movie_ids):\n",
    "        \"\"\" Retorna una tupla amb l'id i el títol de les pel·licules a recomanar. És el resultat final de l'exercici \"\"\"\n",
    "        return [(key, value) for key, value in dict(zip(data.movie_id.unique(), data.title.unique())).iteritems() if key in best_movie_ids]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UserRecomender(CollaborativeFiltering):\n",
    "    \"\"\" Recomender using Collaborative filtering with a User similarity (u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, data_train, similarity=sim_pearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        \n",
    "        # Matriu que conté per cada pel·lícula la puntuació de cada usuari\n",
    "        transformed_data = data_train.pivot_table('rating', index='user_id', columns='movie_id')\n",
    "        \n",
    "        super(UserRecomender, self).__init__(transformed_data, data_train.user_id.unique(), similarity)\n",
    "\n",
    "                \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \"\"\" Given an user_id and a movie_id returns the estimated rating for such movie \"\"\"\n",
    "        return super(UserRecomender, self).estimate(user_id, movie_id)\n",
    "    \n",
    "    \n",
    "    def get_recomendations(self, user_id, n):\n",
    "        \"\"\"Funció que troba les n pel·lícules que el sistema de recomanació considera més recomanables per a l'usuari indicat\"\"\"\n",
    "        all_movies = {movie_id : self.estimate(user_id, movie_id) for movie_id in self.ratings.columns}\n",
    "        return self.get_best_recommendations(all_movies, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5017621392620057"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creació d'una instància de recomanador col·laboratiu basat en semblança d'usuaris.\n",
    "# Es precomputa la matriu de semblances i es realitza una estimació d'exemple (NaN\n",
    "# indicaria que no es tenen suficients dades per estimar una valoració de l'usuari\n",
    "# indicat per a la pel·lícula indicada).\n",
    "user_reco = UserRecomender(movielens_train)\n",
    "user_reco.precompute()\n",
    "user_reco.estimate(user_id=1, movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'error absolut mig és de 0.96220105691 estrelles.\n"
     ]
    }
   ],
   "source": [
    "# S'avalua l'error absolut mig comès \n",
    "mae = evaluate(user_reco.estimate, movielens_test)\n",
    "print \"L'error absolut mig és de\", mae, \"estrelles.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 7\n",
    "\n",
    "+ Desenvolupa un sistema de recomanació col·laboratiu basat en ítems. Si la classe `CollaborativeFiltering` s'ha fet prou genèrica, tan sols caldrà fer petites modificacions a `__init__`, del contrari, podeu fer les modificacions que cregueu necessàries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ItemRecomender(CollaborativeFiltering):\n",
    "    \"\"\" Recomender using Collaborative filtering with a Item similarity (i,i'). \"\"\"\n",
    "    \n",
    "    def __init__(self,data_train, similarity=sim_pearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        \n",
    "        # Matriu que conté per cada pel·lícula la puntuació de cada usuari; és la transposta\n",
    "        # de la del recomanador basat en semblança d'usuaris\n",
    "        transformed_data = data_train.pivot_table('rating', columns='user_id', index='movie_id')\n",
    "        \n",
    "        super(ItemRecomender, self).__init__(transformed_data, data_train.movie_id.unique(), similarity)\n",
    "\n",
    "            \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \"\"\" Given an user_id and a movie_id returns the estimated rating for such movie \"\"\"\n",
    "        \n",
    "        return super(ItemRecomender, self).estimate(movie_id, user_id)\n",
    "    \n",
    "    \n",
    "    def get_recomendations(self, user_id, n):\n",
    "        \"\"\"Funció que troba les n pel·lícules que el sistema de recomanació considera més recomanables per a l'usuari indicat\"\"\" \n",
    "        all_movies = {movie_id : self.estimate(user_id, movie_id) for movie_id in self.ratings.index}\n",
    "        return self.get_best_recommendations(all_movies, n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9555374397378626"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creació d'una instància de recomanador col·laboratiu basat en semblança d'ítems.\n",
    "# Es precomputa la matriu de semblances i es realitza una estimació d'exemple (NaN\n",
    "# indicaria que no es tenen suficients dades per estimar una valoració de l'usuari\n",
    "# indicat per a la pel·lícula indicada).\n",
    "item_reco = ItemRecomender(movielens_train)\n",
    "item_reco.precompute()\n",
    "item_reco.estimate(user_id=2, movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'error absolut mig és de 0.99589840811 estrelles.\n"
     ]
    }
   ],
   "source": [
    "# S'avalua l'error absolut mig comès \n",
    "mae = evaluate(item_reco.estimate, movielens_test)\n",
    "print \"L'error absolut mig és de\", mae, \"estrelles.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCICI 8\n",
    "\n",
    "* Feu un nou mètode `get_recomendations(user_id, n)` que retorni les n pel·lícules recomenades per a l'usuari user_id. De nou, és recomenable fer-ho a la clase pare, `CollaborativeFiltering`, cridant-la des dels fills de forma semblant a com fa `estimate`.\n",
    "\n",
    "* Executeu la funció en els dos recomenadors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I les 5 pel·lícules recomanades són...:\n",
      "\n",
      "[(189, 'Reckless (1995)'), (341, 'Double Happiness (1994)'), (687, 'Country Life (1994)'), (775, 'Spirits of the Dead (Tre Passi nel Delirio) (1968)'), (831, 'Stonewall (1995)')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = user_reco.get_recomendations(1, 5)\n",
    "recommendations_with_titles = user_reco.get_recommendations_with_titles(recommendations)\n",
    "\n",
    "# A continuació es mostren les 5 pel·lícules recomanades a l'usuari en qüestió on el primer valor és\n",
    "# l'id de la pel·lícula i el segoón valor n'és el títol.\n",
    "print \"\\nI les 5 pel·lícules recomanades són...:\\n\\n{}\\n\".format(recommendations_with_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I les 5 pel·lícules recomanades són...:\n",
      "\n",
      "[(114, \"Margaret's Museum (1995)\"), (131, 'Frankie Starlight (1995)'), (183, 'Mute Witness (1994)'), (228, 'Destiny Turns on the Radio (1995)'), (336, 'Walking Dead, The (1995)')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = item_reco.get_recomendations(1, 5)\n",
    "recommendations_with_titles = item_reco.get_recommendations_with_titles(recommendations)\n",
    "\n",
    "# A continuació es mostren les 5 pel·lícules recomanades a l'usuari en qüestió on el primer valor és\n",
    "# l'id de la pel·lícula i el segoón valor n'és el títol.\n",
    "print \"\\nI les 5 pel·lícules recomanades són...:\\n\\n{}\\n\".format(recommendations_with_titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
