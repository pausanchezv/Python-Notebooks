{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autors\n",
    "\n",
    "# - Albert Espín Román\n",
    "# - Pau Sanchez Valdivieso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressió Logística\n",
    "\n",
    "**Nom**: \n",
    "\n",
    "La **regressió logística** és un tipus d'algorisme de classificació binària (vol predir un valor $0$ o $1$ per una determinada mostra) i per fer-ho fa servir la funció logística:\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1+ e^{-x}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpJACncRkQRSuIuIJND/AzHsGEdbuTAaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x42ed400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def logistic(x):\n",
    "\n",
    "    return 1.0 / (1 + math.exp(-x))\n",
    "x = np.linspace(-10,10,200)\n",
    "y = [logistic(_) for _ in x]\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "plt.plot(x,y,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si disposem d'un conjunt de punts $\\{(x_i, y_i)\\}$, on $y_i \\in \\{0,1\\}$, i volem trobar quina és la probabilitat d'una mostra de ser $0$ o $1$ podem aproximar la probabilitat d'aquesta manera:\n",
    "\n",
    "$$ \\hat{y}_i = \\sigma(w x_i) $$\n",
    "\n",
    "on $w$ són una sèrie de pesos que cal determinar. En el cas de la regressió logísitica, la funció de cost que MAXIMITZAREM és la funció que s'anomena *log likelihood*:\n",
    "\n",
    "$$ logL = y_i \\log \\sigma(w x_i) + (1- y_i) \\log (1 - \\sigma(w x_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def logistic_log_likelihood_i(x_i, y_i, beta):\n",
    "    if y_i == 1:\n",
    "        return math.log(logistic(dot(x_i, beta)))\n",
    "    else:\n",
    "        return math.log(1 - logistic(dot(x_i, beta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tant, la funció de cost és:\n",
    "\n",
    "$$ \\sum_{x_i, y_i} y_i \\log \\sigma(w x_i) + (1- y_i) \\log (1 - \\sigma(w x_i)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_log_likelihood(x, y, beta):\n",
    "    return sum(logistic_log_likelihood_i(x_i, y_i, beta)\n",
    "               for x_i, y_i in zip(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Les derivades d'aquestes funcions són simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_log_partial_ij(x_i, y_i, beta, j):\n",
    "    \"\"\"j es l'index de la derivada\"\"\"\n",
    "    return (y_i - logistic(dot(x_i, beta))) * x_i[j]\n",
    "    \n",
    "def logistic_log_gradient_i(x_i, y_i, beta):\n",
    "    \"\"\"gradient de log likelihood pel punt i\"\"\"\n",
    "    return [logistic_log_partial_ij(x_i, y_i, beta, j)\n",
    "            for j, _ in enumerate(beta)]\n",
    "            \n",
    "def logistic_log_gradient(x, y, beta):\n",
    "    return reduce(vector_add,\n",
    "                  [logistic_log_gradient_i(x_i, y_i, beta)\n",
    "                   for x_i, y_i in zip(x,y)])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amb això, i algunes funcions auxililars, tenim tots els ingredients per plantejar el problema com un problema d'optimització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funcions auxiliars\n",
    "from functools import partial\n",
    "\n",
    "def split_data(data, prob):\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "def train_test_split(x, y, test_pct):\n",
    "    data = zip(x, y)                                \n",
    "    train, test = split_data(data, 1 - test_pct)  \n",
    "    x_train, y_train = zip(*train)                \n",
    "    x_test, y_test = zip(*test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def maximize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    return minimize_batch(negate(target_fn),\n",
    "                          negate_all(gradient_fn),\n",
    "                          theta_0, \n",
    "                          tolerance)\n",
    "\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    \n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    theta = theta_0                           # set theta to initial value\n",
    "    target_fn = safe(target_fn)               # safe version of target_fn\n",
    "    value = target_fn(theta)                  # value we're minimizing\n",
    "    \n",
    "    while True:\n",
    "        gradient = gradient_fn(theta)  \n",
    "        next_thetas = [step(theta, gradient, -step_size)\n",
    "                       for step_size in step_sizes]\n",
    "                   \n",
    "        # choose the one that minimizes the error function        \n",
    "        next_theta = min(next_thetas, key=target_fn)\n",
    "        next_value = target_fn(next_theta)\n",
    "        \n",
    "        # stop if we're \"converging\"\n",
    "        if abs(value - next_value) < tolerance:\n",
    "            return theta\n",
    "        else:\n",
    "            theta, value = next_theta, next_value\n",
    "            \n",
    "def rescale(data_matrix):\n",
    "    means, stdevs = scale(data_matrix)\n",
    "\n",
    "    def rescaled(i, j): \n",
    "        if stdevs[j] > 0:\n",
    "            return (data_matrix[i][j] - means[j]) / stdevs[j]\n",
    "        else:\n",
    "            return data_matrix[i][j]\n",
    "\n",
    "    num_rows, num_cols = shape(data_matrix)\n",
    "    return make_matrix(num_rows, num_cols, rescaled)\n",
    "\n",
    "def scale(data_matrix):\n",
    "    num_rows, num_cols = shape(data_matrix)\n",
    "    means = [mean(get_column(data_matrix,j))\n",
    "             for j in range(num_cols)]\n",
    "    stdevs = [standard_deviation(get_column(data_matrix,j))\n",
    "              for j in range(num_cols)]\n",
    "    return means, stdevs\n",
    "\n",
    "def shape(A):\n",
    "    num_rows = len(A)\n",
    "    num_cols = len(A[0]) if A else 0\n",
    "    return num_rows, num_cols\n",
    "\n",
    "def mean(x): \n",
    "    return sum(x) / len(x)\n",
    "\n",
    "def get_column(A, j):\n",
    "    return [A_i[j] for A_i in A]\n",
    "\n",
    "def variance(x):\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    return sum_of_squares(deviations) / (n - 1)\n",
    "    \n",
    "def standard_deviation(x):\n",
    "    return math.sqrt(variance(x))\n",
    "\n",
    "def de_mean(x):\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "def make_matrix(num_rows, num_cols, entry_fn):\n",
    "    \"\"\"returns a num_rows x num_cols matrix \n",
    "    whose (i,j)-th entry is entry_fn(i, j)\"\"\"\n",
    "    return [[entry_fn(i, j) for j in range(num_cols)]\n",
    "            for i in range(num_rows)]  \n",
    "\n",
    "def entry_fn(i, j):\n",
    "    return A[i][j] + B[i][j]\n",
    "\n",
    "def negate(f):\n",
    "    \"\"\"return a function that for any input x returns -f(x)\"\"\"\n",
    "    return lambda *args, **kwargs: -f(*args, **kwargs)\n",
    "\n",
    "def negate_all(f):\n",
    "    \"\"\"the same when f returns a list of numbers\"\"\"\n",
    "    return lambda *args, **kwargs: [-y for y in f(*args, **kwargs)]\n",
    "\n",
    "def safe(f):\n",
    "    \"\"\"define a new function that wraps f and return it\"\"\"\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')         # this means \"infinity\" in Python\n",
    "    return safe_f\n",
    "\n",
    "def vector_add(v, w):\n",
    "    \"\"\"adds two vectors componentwise\"\"\"\n",
    "    return [v_i + w_i for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    \"\"\"move step_size in the direction from v\"\"\"\n",
    "    return [v_i + step_size * direction_i\n",
    "            for v_i, direction_i in zip(v, direction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les dades que farem servir corresponen a una base de dades de 200 usuaris i contenen els seus anys d'experiència, el seu salari i el resultat d'una avaluació interna ($0$ o $1$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.7, 48000], [1, 1.9, 48000]] [1, 0]\n"
     ]
    }
   ],
   "source": [
    "data = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0), \\\n",
    "        (8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0), \\\n",
    "        (1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),   \\\n",
    "        (6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),\\\n",
    "        (8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),\\\n",
    "        (0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),\\\n",
    "        (0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),\\\n",
    "        (8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0), \\\n",
    "        (1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),\\\n",
    "        (7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),\\\n",
    "        (8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),\\\n",
    "        (4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),\\\n",
    "        (8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),\\\n",
    "        (2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),\\\n",
    "        (8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),\\\n",
    "        (2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),\\\n",
    "        (2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),\\\n",
    "        (7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),\\\n",
    "        (8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),\\\n",
    "        (5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),\\\n",
    "        (4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),\\\n",
    "        (4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),\\\n",
    "        (3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),\\\n",
    "        (8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),\\\n",
    "        (1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),\\\n",
    "        (9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),\\\n",
    "        (7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),\\\n",
    "        (2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),\\\n",
    "        (5.1,72000,0),(9.1,69000,1),(9.8,79000,1),]\n",
    "data = map(list, data)              # canviem de tuples a llistes\n",
    "x = [[1] + row[:2] for row in data] # cada element es [1, experiencia, salari]\n",
    "y = [row[2] for row in data]        # cada element es resultat\n",
    "print x[0:2], y[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fet de posar una de les components de $x_i$ a $1$ ens permet que el model lineal que usem pugui ser del tipus $w_0 + w_1 x_1 + w_2 x_2$, atès que $x_0 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat [-1.9061824826642335, 4.053083869380028, -3.878895361783912]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "rescaled_x = rescale(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(rescaled_x, y, 0.33)\n",
    "\n",
    "# want to maximize log likelihood on the training data\n",
    "fn = partial(logistic_log_likelihood, x_train, y_train)\n",
    "gradient_fn = partial(logistic_log_gradient, x_train, y_train)\n",
    "\n",
    "# pick a random starting point\n",
    "w_0 = [1, 1, 1]\n",
    "\n",
    "# and maximize using gradient descent\n",
    "w_hat = maximize_batch(fn, gradient_fn, w_0)\n",
    "\n",
    "print \"w_hat\", w_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 1\n",
    "\n",
    "Avalua el resultat anterior en termes de 'precision' i 'recall'. Consulteu https://en.wikipedia.org/wiki/Precision_and_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Precisió >> 93.33%\n",
      "    Recall >> 82.35%\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solució\n",
    "\n",
    "def obtain_estimation_i(x_test, w_hat, index):\n",
    "    \"\"\" Obté el valor estimat d'un ítem en termes de valor \"\"\"\n",
    "    return logistic(x_test[index][0] * w_hat[0] + x_test[index][1] * w_hat[1] + x_test[index][2] * w_hat[2])\n",
    "\n",
    "def obtain_prediction_i(value):\n",
    "    \"\"\" Obté la predicció d'un ítem en termes 0 o 1 \"\"\"\n",
    "    if value < (1 - 0) / float(2):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def obtain_values_dict():\n",
    "    \"\"\" Crea i retorna el diccionari de valors amb els valors inicialitzats a zero \"\"\"\n",
    "    return {\"true_positives\": 0, \"false_positives\": 0, \"true_negatives\": 0, \"false_negatives\": 0}\n",
    "\n",
    "def obtain_values(x_test, y_test, w_hat):\n",
    "    \"\"\" Avalua el resultat anterior en termes de 'precision i 'recall' \"\"\"\n",
    "    \n",
    "    # Array que guardarà els resultats\n",
    "    results = list()\n",
    "    \n",
    "    # Creem un diccionari que guardarà els valors\n",
    "    all_values = obtain_values_dict()\n",
    "    \n",
    "    # Iterem sobre la longitud de x_test per a fer els càlculs\n",
    "    for i in range(len(x_test)):\n",
    "        \n",
    "        # El valor real ens l'indica el valor de l'element 'i' de y_test\n",
    "        real_value = y_test[i]\n",
    "        \n",
    "        # El valor estimat l'obtenim a partir de dues funcions de suport per millorar la modularització\n",
    "        # i la reutilització del codi\n",
    "        estimate_value = obtain_estimation_i(x_test, w_hat, i)\n",
    "        \n",
    "        # Afegim el valor als resultats\n",
    "        results.append(estimate_value)\n",
    "        \n",
    "        # Transformem el valor a 0 o 1 segons la seva proximitat\n",
    "        estimate_value = obtain_prediction_i(estimate_value)\n",
    "        \n",
    "        # Incrementem els valors segons cada cas\n",
    "        all_values[\"true_positives\"] += int(real_value == estimate_value == 1)\n",
    "        all_values[\"false_positives\"] += int(not real_value and estimate_value)\n",
    "        all_values[\"true_negatives\"] += int(real_value == estimate_value == 0)\n",
    "        all_values[\"false_negatives\"] += int(real_value and not estimate_value)\n",
    "    \n",
    "    # Amb els valors obtinguts obtenim el recall i la precisió demanats\n",
    "    precision = float(all_values['true_positives']) / (all_values['true_positives'] + all_values['false_positives'])* 100\n",
    "    recall = float(all_values['true_positives']) / (all_values['true_positives'] + all_values['false_negatives']) * 100\n",
    "    \n",
    "    return precision, recall, results\n",
    "        \n",
    "precision, recall, results = obtain_values(x_test, y_test, w_hat)\n",
    "\n",
    "print u\"\"\"\n",
    "\n",
    "    Precisió >> {0:.2f}%\n",
    "    Recall >> {1:.2f}%\n",
    "    \n",
    "\"\"\".format(precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 2\n",
    "\n",
    "Feu un gràfic en que l'eix $x$ representi el valor de les prediccions i el $y$ els valors reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD7CAYAAACPDORaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8pJUMENekgpmyEtSwQx5SSqYIS9JBft/aAld/7J0WpAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70cd320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solució\n",
    "\n",
    "# Tot i seguint l'exemple del professorat de l'assignatura de com s'implenenta una gràfica a les cel·les inicials\n",
    "# d'aquest document, s'implementa tot seguit una gràfica que en l'eix de les 'x' representa el valor de les prediccions\n",
    "# i en l'y els valors reals.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y_test dóna vida a la col·lecció de valors reals mentre que la variable results són les prediccions (estimacions)\n",
    "# les quals hem assolit a l'exercici anterior.\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1, 1.1])\n",
    "plt.plot(results, y_test, 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici 3\n",
    "\n",
    "El cas anterior surt d'un nombre random fix (random.seed(0)) i d'un paràmetre fix ([1,1,1]). Feu una cerca aleatoria a veure si es pot trobar un `w_hat` sensiblement millor al [-1.9061824826642335, 4.053083869380028, -3.878895361783912]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.5742491249407413, 5.570416228144058, -5.575773496370661]\n",
      "[-2.6752480750759218, 4.859553338032475, -5.459553640843432]\n",
      "[-2.282043413996983, 5.366070191979021, -4.781452774226474]\n"
     ]
    }
   ],
   "source": [
    "# Aquest exercici l'hem separat en dues cel·les per optimitzar la modularització i la correcta presentació\n",
    "# del codi a desenvolupar.\n",
    "\n",
    "####### IMPORTANT #######\n",
    "\n",
    "# Al treure la llavor (seed), els conjunts d'entrenament i de test es construeixen aleatòriament cada vegada\n",
    "# Si deixéssim els conjunts d'entrenament i de test d'abans NO MILLORARIA els resultats.\n",
    "# PER PODER MILLORAR s'han d'anar generant cada vegada i de fet és així com estem aplicant aleatorietat\n",
    "# absoluta tant a l'w_0 com a les creacions dels conjunts.\n",
    "\n",
    "# REPTIM:: Si no generem conjunts de test i train aleatoris a cada construcció d'un nou w_hat NO MILLORA, de\n",
    "# manera que cada vegada generem conjunts random d'entrenament i de test.\n",
    "\n",
    "#########################\n",
    "\n",
    "# Redefinim els conjunts d'entrenament i de text per poder actualitzar-los globalment\n",
    "# dins la funció.\n",
    "x_train, x_test, y_train, y_test = tuple([None] * 4)\n",
    "\n",
    "def get_random_w_hat(x, y):\n",
    "    \"\"\" Funció que retorna un generador de w_hat \"\"\"\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    # Itera sense fi tot i generant un w_hat diferents a cada crida 'next' (recordar que estem en un\n",
    "    # generador)\n",
    "    while(True):\n",
    "\n",
    "        rescaled_x = rescale(x)\n",
    "        \n",
    "        global x_train, x_test, y_train, y_test\n",
    "        x_train, x_test, y_train, y_test = train_test_split(rescaled_x, y, 0.33)\n",
    "\n",
    "        # want to maximize log likelihood on the training data\n",
    "        fn = partial(logistic_log_likelihood, x_train, y_train)\n",
    "        gradient_fn = partial(logistic_log_gradient, x_train, y_train)\n",
    "\n",
    "        # pick a random starting point\n",
    "        w_0 = [random.randint(0, 2), random.randint(0, 2), random.randint(0, 2)]\n",
    "\n",
    "        # and maximize using gradient descent\n",
    "        w_hat = maximize_batch(fn, gradient_fn, w_0)\n",
    "        \n",
    "        yield w_hat\n",
    "\n",
    "# Crida al generador amb x i y que sempre representen el mateix conjunt de dades global\n",
    "w_hat_gen = get_random_w_hat(x, y)\n",
    "\n",
    "# Mostra com a cada crida next al generador retorna un w_hat ramdom diferent\n",
    "print w_hat_gen.next()\n",
    "print w_hat_gen.next()\n",
    "print w_hat_gen.next()\n",
    "# etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    *** Valors anteriors ***\n",
      "    \n",
      "    Precisió anterior >> 93.33\n",
      "    Recall anterior >> 82.35\n",
      "    W_Hat anterior >> [-1.9061824826642335, 4.053083869380028, -3.878895361783912]\n",
      "    \n",
      "    *** Valors millorats ***\n",
      "    \n",
      "    Precisió millorada >> 93.75\n",
      "    Recall millorat >> 83.33\n",
      "    W_Hat de la millora >> [-2.054350693321647, 4.1738352053946, -4.075839720572922]\n",
      "    \n",
      "    Cal tenir en compte que els conjunts d'entrenament i de test poden haver canviat, en canvi,\n",
      "    les dades de ben segur que no han canviat. Si no s'anaven generant conjunts d'entrenament\n",
      "    i de test a cada crida al generador w_hat no hi havia manera de millorar el resultat anterior.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def upgrade_w_hat(old_precision, old_recall):\n",
    "    \"\"\" Funció que millora aleatoriament les dades anteriors \"\"\"\n",
    "    \n",
    "    # Inicialitzem les variables que guardaran els millors paràmetres precisió, recall i w_hat extrets\n",
    "    # aletòriament amb el generador proposat a la cel·la anterior\n",
    "    best_precision, best_recall, best_w_hat = 0, 0, None\n",
    "\n",
    "    # Itera fins a millorar la precisió i el recall anteriors\n",
    "    while best_precision <= old_precision or best_recall <= old_recall:\n",
    "\n",
    "        # Generem un nou w_hat aleatori \n",
    "        current_w_hat = w_hat_gen.next()\n",
    "\n",
    "        # N'obtenim els valors\n",
    "        precision, recall, _ = obtain_values(x_test, y_test, current_w_hat)\n",
    "\n",
    "        # Actualitzem els valors si escau\n",
    "        if precision > best_precision or recall > best_recall:\n",
    "            best_precision, best_recall, best_w_hat = precision, recall, current_w_hat\n",
    "            \n",
    "    return best_precision, best_recall, best_w_hat\n",
    "\n",
    "\n",
    "# Els valors passats com a paràmetres al fer la crida son la precisió i el recall anteriors, és a dir,\n",
    "# la precisió i el recall que hem de millorar trobant un w_hat millor.\n",
    "best_precision, best_recall, best_w_hat = upgrade_w_hat(precision, recall)\n",
    "\n",
    "print u\"\"\"\n",
    "\n",
    "    *** Valors anteriors ***\n",
    "    \n",
    "    Precisió anterior >> {0:.2f}\n",
    "    Recall anterior >> {1:.2f}\n",
    "    W_Hat anterior >> {2}\n",
    "    \n",
    "    *** Valors millorats ***\n",
    "    \n",
    "    Precisió millorada >> {3:.2f}\n",
    "    Recall millorat >> {4:.2f}\n",
    "    W_Hat de la millora >> {5}\n",
    "    \n",
    "    Cal tenir en compte que els conjunts d'entrenament i de test poden haver canviat, en canvi,\n",
    "    les dades de ben segur que no han canviat. Si no s'anaven generant conjunts d'entrenament\n",
    "    i de test a cada crida al generador w_hat no hi havia manera de millorar el resultat anterior.\n",
    "\n",
    "\n",
    "\"\"\".format(precision, recall, w_hat, best_precision, best_recall, best_w_hat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
